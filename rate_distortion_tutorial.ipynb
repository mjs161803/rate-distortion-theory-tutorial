{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rate Distortion Theory Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Rate Distortion Theory** is a fundamental concept in information theory developed by **Claude Shannon** in 1948-1959. It addresses the fundamental trade-off between the rate of data compression and the distortion (quality loss) that results from compression.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Rate (R)**: The number of bits per source symbol needed to represent the data after compression.\n",
    "2. **Distortion (D)**: A measure of the difference between the original and reconstructed data.\n",
    "3. **Rate-Distortion Function R(D)**: The minimum rate needed to achieve a given distortion level.\n",
    "\n",
    "Shannon's key insight was that for any given distortion level D, there exists a theoretical minimum rate R(D) below which it's impossible to compress the data without exceeding that distortion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Foundation\n",
    "\n",
    "For a memoryless source with distribution $p(x)$, the rate-distortion function is defined as:\n",
    "\n",
    "$$R(D) = \\min_{p(\\hat{x}|x): E[d(X,\\hat{X})] \\leq D} I(X;\\hat{X})$$\n",
    "\n",
    "where:\n",
    "- $I(X;\\hat{X})$ is the mutual information between the source $X$ and reconstruction $\\hat{X}$\n",
    "- $d(X,\\hat{X})$ is the distortion measure\n",
    "- $E[d(X,\\hat{X})]$ is the expected distortion\n",
    "\n",
    "### Gaussian Source Example\n",
    "\n",
    "For a Gaussian source with variance $\\sigma^2$ and squared error distortion, the rate-distortion function has a closed form:\n",
    "\n",
    "$$R(D) = \\begin{cases} \n",
    "\\frac{1}{2}\\log_2\\left(\\frac{\\sigma^2}{D}\\right) & \\text{if } D < \\sigma^2 \\\\\n",
    "0 & \\text{if } D \\geq \\sigma^2\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate-Distortion Function for Gaussian Source\n",
    "\n",
    "Let's implement and visualize the rate-distortion function for a Gaussian source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_distortion_gaussian(D, sigma_squared):\n",
    "    \"\"\"\n",
    "    Calculate the rate-distortion function for a Gaussian source.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    D : float or array\n",
    "        Distortion level(s)\n",
    "    sigma_squared : float\n",
    "        Variance of the Gaussian source\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    R : float or array\n",
    "        Rate in bits per symbol\n",
    "    \"\"\"\n",
    "    D = np.array(D)\n",
    "    R = np.zeros_like(D)\n",
    "    \n",
    "    # Only calculate for D < sigma_squared\n",
    "    mask = D < sigma_squared\n",
    "    R[mask] = 0.5 * np.log2(sigma_squared / D[mask])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def plot_rate_distortion(sigma_squared=1.0):\n",
    "    \"\"\"\n",
    "    Plot the rate-distortion function for a Gaussian source.\n",
    "    \"\"\"\n",
    "    # Create distortion range\n",
    "    D_max = sigma_squared * 1.5\n",
    "    D = np.linspace(0.001, D_max, 1000)\n",
    "    \n",
    "    # Calculate rate-distortion function\n",
    "    R = rate_distortion_gaussian(D, sigma_squared)\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(D, R, 'b-', linewidth=2, label=f'R(D) for σ² = {sigma_squared}')\n",
    "    ax.axvline(x=sigma_squared, color='r', linestyle='--', \n",
    "               label=f'D = σ² = {sigma_squared}', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Distortion (D)', fontsize=12)\n",
    "    ax.set_ylabel('Rate (R) [bits/symbol]', fontsize=12)\n",
    "    ax.set_title('Rate-Distortion Function for Gaussian Source', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(0, D_max)\n",
    "    ax.set_ylim(0, max(R) * 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display static plot\n",
    "plot_rate_distortion(sigma_squared=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Exploration\n",
    "\n",
    "Use the slider below to adjust the source variance (σ²) and observe how the rate-distortion curve changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widget\n",
    "interactive_plot = widgets.interactive(\n",
    "    plot_rate_distortion,\n",
    "    sigma_squared=widgets.FloatSlider(\n",
    "        value=1.0,\n",
    "        min=0.1,\n",
    "        max=5.0,\n",
    "        step=0.1,\n",
    "        description='Variance (σ²):',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    ")\n",
    "\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Example: Signal Compression\n",
    "\n",
    "Let's demonstrate rate-distortion theory with a practical example: compressing a Gaussian signal.\n",
    "\n",
    "We'll:\n",
    "1. Generate a random Gaussian signal\n",
    "2. Compress it using uniform quantization (a simple compression method)\n",
    "3. Calculate the resulting rate and distortion\n",
    "4. Compare with the theoretical rate-distortion bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_quantizer(signal, num_levels):\n",
    "    \"\"\"\n",
    "    Quantize a signal uniformly.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal : array\n",
    "        Input signal\n",
    "    num_levels : int\n",
    "        Number of quantization levels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    quantized : array\n",
    "        Quantized signal\n",
    "    \"\"\"\n",
    "    signal_min = signal.min()\n",
    "    signal_max = signal.max()\n",
    "    \n",
    "    # Create quantization boundaries\n",
    "    boundaries = np.linspace(signal_min, signal_max, num_levels + 1)\n",
    "    levels = (boundaries[:-1] + boundaries[1:]) / 2\n",
    "    \n",
    "    # Quantize\n",
    "    indices = np.digitize(signal, boundaries) - 1\n",
    "    indices = np.clip(indices, 0, num_levels - 1)\n",
    "    quantized = levels[indices]\n",
    "    \n",
    "    return quantized\n",
    "\n",
    "def calculate_mse(original, reconstructed):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error.\n",
    "    \"\"\"\n",
    "    return np.mean((original - reconstructed) ** 2)\n",
    "\n",
    "def demonstrate_compression(signal_length=1000, sigma_squared=1.0, num_levels=16):\n",
    "    \"\"\"\n",
    "    Demonstrate signal compression and compare with rate-distortion bound.\n",
    "    \"\"\"\n",
    "    # Generate Gaussian signal\n",
    "    signal = np.random.normal(0, np.sqrt(sigma_squared), signal_length)\n",
    "    \n",
    "    # Quantize signal\n",
    "    quantized = uniform_quantizer(signal, num_levels)\n",
    "    \n",
    "    # Calculate distortion (MSE)\n",
    "    distortion = calculate_mse(signal, quantized)\n",
    "    \n",
    "    # Calculate rate (bits per sample)\n",
    "    rate = np.log2(num_levels)\n",
    "    \n",
    "    # Theoretical rate-distortion bound\n",
    "    D_range = np.linspace(0.001, sigma_squared, 1000)\n",
    "    R_theoretical = rate_distortion_gaussian(D_range, sigma_squared)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Original vs Quantized Signal (first 200 samples)\n",
    "    ax1 = axes[0, 0]\n",
    "    sample_range = min(200, signal_length)\n",
    "    ax1.plot(signal[:sample_range], 'b-', alpha=0.7, label='Original', linewidth=1)\n",
    "    ax1.plot(quantized[:sample_range], 'r-', alpha=0.7, label='Quantized', linewidth=1)\n",
    "    ax1.set_xlabel('Sample Index')\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    ax1.set_title('Original vs Quantized Signal (First 200 samples)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Error signal\n",
    "    ax2 = axes[0, 1]\n",
    "    error = signal - quantized\n",
    "    ax2.plot(error[:sample_range], 'g-', linewidth=1)\n",
    "    ax2.set_xlabel('Sample Index')\n",
    "    ax2.set_ylabel('Error')\n",
    "    ax2.set_title(f'Quantization Error (MSE = {distortion:.4f})')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Rate-Distortion curve with operating point\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(D_range, R_theoretical, 'b-', linewidth=2, label='Theoretical R(D)')\n",
    "    ax3.plot(distortion, rate, 'ro', markersize=10, label=f'Operating Point\\n(R={rate:.2f}, D={distortion:.4f})')\n",
    "    ax3.axhline(y=rate, color='r', linestyle='--', alpha=0.3)\n",
    "    ax3.axvline(x=distortion, color='r', linestyle='--', alpha=0.3)\n",
    "    ax3.set_xlabel('Distortion (D)')\n",
    "    ax3.set_ylabel('Rate (R) [bits/symbol]')\n",
    "    ax3.set_title('Rate-Distortion Function')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_xlim(0, sigma_squared * 1.2)\n",
    "    \n",
    "    # Plot 4: Histograms\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.hist(signal, bins=50, alpha=0.5, label='Original', density=True)\n",
    "    ax4.hist(quantized, bins=num_levels, alpha=0.5, label='Quantized', density=True)\n",
    "    \n",
    "    # Add theoretical Gaussian\n",
    "    x = np.linspace(signal.min(), signal.max(), 100)\n",
    "    ax4.plot(x, stats.norm.pdf(x, 0, np.sqrt(sigma_squared)), 'k-', \n",
    "             linewidth=2, label='Theoretical Gaussian')\n",
    "    \n",
    "    ax4.set_xlabel('Amplitude')\n",
    "    ax4.set_ylabel('Density')\n",
    "    ax4.set_title('Distribution Comparison')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"COMPRESSION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Source variance (σ²):        {sigma_squared:.4f}\")\n",
    "    print(f\"Number of quantization levels: {num_levels}\")\n",
    "    print(f\"Rate (bits/symbol):          {rate:.4f}\")\n",
    "    print(f\"Distortion (MSE):            {distortion:.4f}\")\n",
    "    print(f\"Theoretical R(D):            {rate_distortion_gaussian(distortion, sigma_squared):.4f}\")\n",
    "    print(f\"Rate gap from bound:         {rate - rate_distortion_gaussian(distortion, sigma_squared):.4f} bits/symbol\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Run demonstration\n",
    "demonstrate_compression(signal_length=1000, sigma_squared=1.0, num_levels=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Compression Demo\n",
    "\n",
    "Adjust the parameters below to explore how different quantization levels affect the rate-distortion trade-off:\n",
    "\n",
    "- **Variance (σ²)**: Controls the power of the source signal\n",
    "- **Quantization Levels**: Number of discrete levels used to represent the signal (determines the rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive demonstration\n",
    "interactive_demo = widgets.interactive(\n",
    "    demonstrate_compression,\n",
    "    signal_length=widgets.fixed(1000),\n",
    "    sigma_squared=widgets.FloatSlider(\n",
    "        value=1.0,\n",
    "        min=0.5,\n",
    "        max=3.0,\n",
    "        step=0.1,\n",
    "        description='Variance (σ²):',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    num_levels=widgets.IntSlider(\n",
    "        value=16,\n",
    "        min=4,\n",
    "        max=256,\n",
    "        step=4,\n",
    "        description='Quantization Levels:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    ")\n",
    "\n",
    "display(interactive_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "From the interactive examples above, you should observe:\n",
    "\n",
    "1. **Trade-off**: As you increase the number of quantization levels:\n",
    "   - Rate (R) increases (more bits needed per sample)\n",
    "   - Distortion (D) decreases (better quality reconstruction)\n",
    "\n",
    "2. **Theoretical Bound**: The operating point (red dot) is always above or on the theoretical R(D) curve. This is because:\n",
    "   - The R(D) curve represents the theoretical minimum\n",
    "   - Uniform quantization is not optimal (but simple to implement)\n",
    "   - Optimal codes can get closer to the R(D) bound\n",
    "\n",
    "3. **Source Variance Effect**: Higher source variance requires:\n",
    "   - More bits to achieve the same distortion level\n",
    "   - The R(D) curve shifts upward\n",
    "\n",
    "4. **Diminishing Returns**: The rate-distortion curve shows that:\n",
    "   - Small distortions require exponentially more bits\n",
    "   - There's a \"sweet spot\" for practical applications\n",
    "   - Beyond the source variance, no bits are needed (R = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Rate Distortion Theory\n",
    "\n",
    "Rate distortion theory has numerous practical applications:\n",
    "\n",
    "1. **Image and Video Compression** (JPEG, MPEG, H.264, H.265)\n",
    "   - Determines optimal bit allocation\n",
    "   - Guides perceptual coding strategies\n",
    "\n",
    "2. **Audio Compression** (MP3, AAC, Opus)\n",
    "   - Balances file size vs audio quality\n",
    "   - Perceptual coding based on human hearing\n",
    "\n",
    "3. **Wireless Communications**\n",
    "   - Channel coding and modulation design\n",
    "   - Adaptive coding based on channel conditions\n",
    "\n",
    "4. **Data Storage**\n",
    "   - Optimizing storage efficiency\n",
    "   - Lossy compression for large datasets\n",
    "\n",
    "5. **Machine Learning**\n",
    "   - Neural network quantization\n",
    "   - Model compression for edge devices\n",
    "   - Information bottleneck principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Rate Distortion Theory** provides a fundamental framework for understanding lossy compression:\n",
    "\n",
    "- Developed by Claude Shannon as part of information theory\n",
    "- Establishes theoretical limits on compression efficiency\n",
    "- The rate-distortion function R(D) defines the minimum rate for a given distortion\n",
    "- For Gaussian sources: $R(D) = \\frac{1}{2}\\log_2\\left(\\frac{\\sigma^2}{D}\\right)$ for $D < \\sigma^2$\n",
    "- Practical compression schemes approach but cannot exceed the R(D) bound\n",
    "- Essential for designing efficient compression algorithms across many domains\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "1. Shannon, C. E. (1959). \"Coding theorems for a discrete source with a fidelity criterion\"\n",
    "2. Cover, T. M., & Thomas, J. A. (2006). \"Elements of Information Theory\" (Chapter 10)\n",
    "3. Berger, T. (1971). \"Rate Distortion Theory: A Mathematical Basis for Data Compression\"\n",
    "\n",
    "---\n",
    "\n",
    "**Experiment with the interactive widgets above to develop intuition about rate-distortion trade-offs!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
